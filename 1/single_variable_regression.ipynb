{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f7843617",
   "metadata": {},
   "source": [
    "# 单变量线性回归\n",
    "## 导入模块"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c13da0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca2e9a11",
   "metadata": {},
   "source": [
    "## 读取训练样本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b1f6f3de-9862-44f8-9c15-e0c201b0cf7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def readSample(path):\n",
    "    data = pd.read_csv(path, header=None, names=['population', 'profit'])\n",
    "    print(data.head())\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa47b2a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    path = \"C:/Users/l30072207/Documents/ml/1/ex1data1.txt\"\n",
    "    data = readSample(path)\n",
    "    data.plot(kind='scatter', x='population', y='profit', figsize=(12,8))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf6bc8dd",
   "metadata": {},
   "source": [
    "## 梯度下降\n",
    "### 代价函数\n",
    "$$J(\\theta)=\\frac{1}{2m}\\sum_{i=1}^{m}(h_{\\theta}(x^{(i)})-y^{(i)})^2$$\n",
    "$$h_{\\theta}(x^{(i)})=\\theta_0+\\theta_1x^{(i)}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "775c0db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeCost(X, y, theta):\n",
    "    inner = np.power(((X @ theta) - y), 2) # ndarray使用@表示矩阵乘法，*表示逐元素相乘\n",
    "    return np.sum(inner) / (2 * len(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b41e8e55",
   "metadata": {},
   "source": [
    "### 初始化X、y、$\\theta$\n",
    "特征X添加$\\theta_0$对应特征列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2521a1df",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    data.insert(0, 'ones', 1)\n",
    "    cols=data.shape[1]\n",
    "    X = data.iloc[:, :-1]\n",
    "    y = data.iloc[:, cols-1:cols] # 第二维直接用-1会忽略第一行名称\n",
    "    print(X.head())\n",
    "    print(y.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3375d875",
   "metadata": {},
   "source": [
    "转换为ndarray矩阵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "038de78d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    X = X.to_numpy()\n",
    "    y = y.to_numpy()\n",
    "    theta = np.zeros((2, 1), dtype=np.float32)\n",
    "    print(f\"X:维度{X.shape}\\n{X[:5, :]}\")\n",
    "    print(f\"y:维度{y.shape}\\n{y[:5]}\")\n",
    "    print(f\"theta:维度{theta.shape}\\n{theta}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4703f999",
   "metadata": {},
   "source": [
    "### 计算初始代价函数值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c9954a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    cost = computeCost(X, y, theta)\n",
    "    print(f\"代价函数初始值为：{cost:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08add653",
   "metadata": {},
   "source": [
    "### 梯度下降算法求解使代价函数局部最小时的$\\theta$\n",
    "$$\\begin{align*}\n",
    "\\theta_j&=\\theta_j-\\alpha\\frac{\\partial}{\\partial \\theta_j}J(\\theta)\\\\\n",
    "&=\\theta_j-\\frac{\\alpha}{m}\\sum_{i=1}^m(h_{\\theta}(x^{(i)})-y^{(i)})x_j^{(i)}\\quad(j=0,...,n)\n",
    "\\end{align*}$$\n",
    "注意：需同时更新$\\theta_j$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e06f9ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradientDescent(X, y, theta, alpha, iters):\n",
    "    cost = np.zeros(iters)\n",
    "    \n",
    "    for iter in range(iters):\n",
    "        error = X @ theta - y\n",
    "        grad = 1 / len(X) * (X.T @ error)\n",
    "        theta -= alpha * grad\n",
    "        cost[iter] = computeCost(X, y, theta)\n",
    "    return theta, cost\n",
    "\n",
    "def plotFitCurve(data, theta):\n",
    "    x = np.linspace(data.population.min(), data.profit.max(), 100)\n",
    "    h = theta[0,0] + theta[1,0] * x\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(12,8))\n",
    "    ax.plot(x, h, 'r', label='Prediction')\n",
    "    ax.scatter(data.population, data.profit, label='Training Data')\n",
    "    ax.legend() # 自动显示图例\n",
    "    ax.set_xlabel('Population')\n",
    "    ax.set_ylabel('Profit')\n",
    "    ax.set_title('Predicted Profit vs. Population Size')\n",
    "\n",
    "def plotCostConvergence(cost):\n",
    "    plt.figure(figsize=(12,8))\n",
    "\n",
    "    # 绘制曲线\n",
    "    plt.plot(range(len(cost)), cost, 'r', linewidth=2)\n",
    "    \n",
    "    # 添加装饰 (f-string 用法)\n",
    "    plt.title(f\"Cost Function Convergence (Final Cost: {cost[-1]:.4f})\")\n",
    "    plt.xlabel(\"Iterations\")\n",
    "    plt.ylabel(\"Cost J(theta)\")\n",
    "    \n",
    "    # 添加网格方便观察\n",
    "    plt.grid(True, linestyle='--', alpha=0.6)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    alpha = 0.01\n",
    "    iters = 1500\n",
    "    theta, cost = gradientDescent(X, y, theta, alpha, iters)\n",
    "\n",
    "    plotCostConvergence(cost)\n",
    "    \n",
    "    print(f\"predict1:{np.array([[1,3.5]])@theta}\")\n",
    "    print(f\"predict2:{np.array([[1,7]])@theta}\")\n",
    "\n",
    "    plotFitCurve(data, theta)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
